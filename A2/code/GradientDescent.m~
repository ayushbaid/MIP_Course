function [x,logCost,iter] = GradientDescent(xInit,y,g,maxIters,alpha)
%GradientDescent Implements adaptive gradient descent using potential function
%for MRF and other params passed as arguments

x = xInit;
stepSize=0.1; % Initial step size
gradientThreshold = 0.01; % Threshold for gradient change

logCostArray = zeros(maxIter,1); 


[logCost,grad] = MRFEval(x,g)+GetLikelihoodTerm(x,y);

iter=1;
while(1)

    if max(max(grad))<gradientThreshold && iter<maxIters
        break
    end
    xNew = x-stepSize*grad;
    
    [newLogCost2,newGrad2] = MRFEval(xNew,g);
    [newLogCost1,newGrad1] = GetLikelihoodTerm(xNew,y);
    
    newLogCost = lambda*newLogCost1*(1-lambda)*new
    
    if newLogCost<logCost
        x = xNew;
        stepSize = stepSize*1.1;
        logCostArray(iter)=logCost;
        iter=iter+1;
    else
        stepSize = stepSize*0.5;
    end
    
    logCost = newLogCost;
    grad = newGrad;
end

